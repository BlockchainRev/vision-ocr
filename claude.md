# Vision OCR - Document Processing with Confidence Scoring

## ğŸ¯ Project Goal

Convert **unstructured documents** (PDFs, images) into **structured data** with confidence scoring for production-grade accuracy.

**Pipeline:**
1. Extract text from each page using vision LLMs (parallelized)
2. Run multiple models for consensus voting
3. Output structured JSON with confidence scores
4. Flag low-confidence fields for human review

## ğŸ” Best Practice: Always Web Search First

**IMPORTANT**: Before using any tool or library, **search the internet** to find the best option.

Example from this project:
- âŒ Didn't search â†’ Used `pdf-poppler` â†’ Failed (missing system dependencies)
- âœ… Searched â†’ Found `pdf-to-png-converter` â†’ Works perfectly (no dependencies)

**Always research before implementing:**
```bash
# Search for: "best nodejs pdf to png converter 2025"
# Compare options, check compatibility, read reviews
# Then implement the winner
```

## ğŸš€ How to Run

### Setup
```bash
# Install dependencies
npm install

# Create .env file with your API key
echo "GROQ_API_KEY=your_key_here" > .env
```

### Build
```bash
npm run build
```

### Run OCR
```bash
npm test
```

### Output
- Results saved to `output/{filename}_{timestamp}.md`
- Each run creates a unique timestamped file

## ğŸ“ Project Structure

```
vision-ocr/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ index.ts          # Core OCR logic with PDF support
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ index.ts          # Test runner
â”‚   â”œâ”€â”€ image.png         # Test image
â”‚   â””â”€â”€ 106587.pdf        # Test PDF
â”œâ”€â”€ output/               # Generated markdown files
â””â”€â”€ .env                  # API keys (not in git)
```

## ğŸ§  How It Works

### Current Implementation
1. **PDF â†’ PNG**: Converts PDF pages to images using `pdf-to-png-converter`
2. **Parallel Processing**: Processes all pages simultaneously
3. **Vision Model**: Uses `meta-llama/llama-4-scout-17b-16e-instruct` via Groq
4. **Markdown Output**: Extracts text and formats as clean markdown
5. **Merge**: Combines pages in order with `---` separators

### Upcoming: Multi-Model Confidence Scoring
- Run 3 vision models in parallel
- Compare outputs using consensus voting
- Calculate confidence scores per field
- Flag uncertain extractions for review

## ğŸ”§ Models Used

- **Primary**: `meta-llama/llama-4-scout-17b-16e-instruct` (Groq)
- Vision model with 128K context window
- Supports multilingual, multi-turn conversations

## ğŸ“Š Confidence Thresholds (Planned)

- **High (â‰¥0.85)**: Auto-approve
- **Medium (0.65-0.85)**: Flag for review
- **Low (<0.65)**: Reject or manual processing

## ğŸ’¡ Tips

1. **Always search before coding** - Find the best tool/library first
2. **Use parallelization** - Process pages simultaneously for speed
3. **Structured output** - JSON enables better validation than raw text
4. **Confidence scoring** - Essential for production document processing
5. **Unique filenames** - Timestamp prevents overwriting results
